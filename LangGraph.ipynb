{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP6TKnFAiHG3xcw1klFHby5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaehakimm/Langgraph/blob/main/LangGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
      ],
      "metadata": {
        "id": "zdY-8liQPfrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StGZgYTOQDHr",
        "outputId": "e21967d4-8d3f-4fd5-ade5-539a7a2d2380"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "gpt4omini_chat = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "v6LnqiT1Q50H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "msg = HumanMessage(content=\"Hello world\", name=\"kwan\")\n",
        "gpt35_chat([msg])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vBXpstbSKpK",
        "outputId": "27105e27-a11d-4d42-8e60-67fbe06761b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7173057f-6bc4-47ee-a552-f71ef2c3c394-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_set_env(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRglIz9ZTAXm",
        "outputId": "440c6a7b-c3b1-4b41-dbcd-f230f7970531"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TAVILY_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tavilysearch = TavilySearchResults(maxresult=2)\n",
        "searchdoc = tavilysearch.invoke(\"what is agentic ai\")\n"
      ],
      "metadata": {
        "id": "kxeddvdITgR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "searchdoc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFrcKnPoUkHO",
        "outputId": "f373801b-4e28-43c2-b83f-3cee29e17a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://www.techtarget.com/searchenterpriseai/definition/agentic-AI',\n",
              "  'content': 'What Is Agentic AI? What is agentic AI? Agentic AI refers to artificial intelligence systems that are capable of autonomous action and decision-making. Even if agentic AI systems are guided by goals that humans initially define, they can act alone and are capable of free-form interactions with the real world, e.g., robotics, or with virtual environments, e.g., simulations. Because agentic AI systems dynamically change their behavior when their environment changes, they could handle new or ambiguous information without having to turn to a human for guidance. Complex agentic AI systems that require extensive computational resources could consume significant amounts of energy, resulting in environmental damage and high operational costs.'},\n",
              " {'url': 'https://www.rpatech.ai/agentic-ai/',\n",
              "  'content': 'What is Agentic AI? Agentic AI refers to intelligent systems capable of autonomous action, decision-making, and goal-oriented behaviours. Unlike traditional AI systems that require specific instructions, Agentic AI operates independently, learning from its environment and adapting its behaviour in real-time to achieve objectives. Agentic AI: Often deployed in dynamic, operational environments like autonomous vehicles, robotics, or smart city infrastructure. Agentic AI By combining their strengths, Agentic and Generative AI can create systems capable of ideation and execution, such as autonomous marketing assistants that craft campaigns and deploy them autonomously. Benefits of Agentic AI Challenges of Agentic AI Agentic AI, known for its goal-oriented and autonomous behaviour, can synergize with Generative AI, which excels in creating content such as text, images, and code.'},\n",
              " {'url': 'https://konghq.com/blog/learning-center/agentic-ai',\n",
              "  'content': \"Kong AI Gateway As it interacts with its surroundings, agentic AI is constantly collecting data, learning, and refining its decision-making processes. Whether it's an autonomous vehicle moving to avoid an obstacle in its path or a security system detecting and responding to potential digital threats, these real-time capabilities make agentic AI competitive in dynamic, fast-paced environments such as healthcare, robotics, or finance. Efficiency and productivity: Because agentic AI systems can perform complex tasks independently, very little human oversight is needed, if any. Data privacy concerns: Agentic AI systems rely heavily on data to make decisions, and the more data they have to process, the better they can perform over time. A: Agentic AI is a type of artificial intelligence that operates autonomously, executing tasks, making decisions, and interacting with its surroundings independently, without continuous human intervention.\"},\n",
              " {'url': 'https://www.salesforce.com/agentforce/what-is-agentic-ai/',\n",
              "  'content': \"What is Agentic AI? What is Agentic AI? Learn how agentic AI is using data and artificial intelligence to help businesses boost employee productivity, drive innovation, and unlock new revenue streams. This platform has a suite of tools and services to help AI agents learn, adapt, and collaborate so they can quickly handle complex and dynamic tasks. With this framework, businesses can customize AI agents to meet their specific needs, whether those needs involve automating repetitive tasks, enhancing customer service, or driving strategic decision-making. Agentic AI uses self-contained agents — AI models that autonomously complete tasks and manage workflows using machine learning, algorithms, and predictive analytics to make real-time decisions. What's next for agentic AI?\"},\n",
              " {'url': 'https://www.ibm.com/think/insights/agentic-ai',\n",
              "  'content': 'Agentic AI gets us closer to the use cases that we, until recently, thought of as science fiction, where machines can complete complex tasks involving complex workflows, data-driven decision-making and action-taking with minimal human intervention. Agentic AI systems provide the best of both worlds: using LLMs to handle tasks that benefit from flexibility and dynamic responses, while combining these AI capabilities with traditional programming for strict rules, logic and performance. Agentic AI can use feedback loops where it actively seeks out new data to refine its models or decision-making processes. For example, an agentic AI could be tasked with managing a marketing campaign, continuously monitoring performance, adjusting strategies and optimizing results based on feedback without the need for human input at every step.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Module 1 **\n",
        "\n",
        "**LangGraph Arcademy**\n",
        "\n",
        "# Simple Graph"
      ],
      "metadata": {
        "id": "DdWile06UvzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph"
      ],
      "metadata": {
        "id": "_dlKzatTU0e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# State\n",
        "\n",
        "First define a state of Graph\n",
        "For ? = input schema of workflow of graph, edge, node\n",
        "use Typedict class from Python Typing module as Schema"
      ],
      "metadata": {
        "id": "gNRuEXlhahdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "class state(TypedDict):\n",
        "  graph_state: str"
      ],
      "metadata": {
        "id": "ebJ9cietZ7TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node\n",
        "\n",
        "node = python function.. So the first position of Argument is State that define above. The reason is state is a typedict with Schema, all node can access the key graph_state with state['graph_state']\n",
        "\n",
        "each node return a new value of the state in key graph_state\n",
        "\n",
        "**important**\n",
        "\n",
        "By default a new value return by each node  will overried the previouse state value"
      ],
      "metadata": {
        "id": "KGg6fmovbPSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node1 (state):\n",
        "  print(\"node1------------------\")\n",
        "  return {\"graph_state\": state['graph_state']+\"ฉันนั้น\"}\n",
        "\n",
        "def node2 (state):\n",
        "  print(\"node2------------------\")\n",
        "  return {\"graph_state\":state['graph_state']+\"สบายดี\"}\n",
        "\n",
        "def node3 (state):\n",
        "  print(\"node3------------------\")\n",
        "  return{\"graph_state\":state['graph_state']+\"ไม่สบาย\"}\n"
      ],
      "metadata": {
        "id": "jtw_XkoNc-yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Edge**\n",
        "Edge = connect to node\n",
        "\n",
        "normal edge = normal edge always work like this node 1 => node 2\n",
        "\n",
        "condition edge = want to customize or optional route between node\n",
        "\n",
        "condition edge are implement as function  the return next node"
      ],
      "metadata": {
        "id": "SgSBYL5vel0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from typing import Literal\n",
        "\n",
        "def decide_mood(state) -> Literal[\"node2\", \"node3\"]:\n",
        "\n",
        "    # Often, we will use state to decide on the next node to visit\n",
        "    user_input = state['graph_state']\n",
        "\n",
        "    # Here, let's just do a 50 / 50 split between nodes 2, 3\n",
        "    if random.random() < 0.5:\n",
        "\n",
        "        # 50% of the time, we return Node 2\n",
        "        return \"node2\"\n",
        "\n",
        "    # 50% of the time, we return Node 3\n",
        "    return \"node3\""
      ],
      "metadata": {
        "id": "EAqNF053fiuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph Construction**\n",
        "\n",
        "from the all component that created State,node, edge . From now will build Graph\n",
        "\n",
        "use StateGraph class is the Graphclass that have to use\n",
        "\n",
        "1. initialize a StateGraph with the State class we defined\n",
        "2. add our nodes and edges.\n",
        "3. use the START Node, a special node that sends user input to the graph, to indicate where to start our graph\n",
        "4. END Node is a special node that represents a terminal node\n",
        "\n",
        "last, compile our graph to perform a few basic checks on the graph structure.\n"
      ],
      "metadata": {
        "id": "TDk_DozGgunK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "#initialize a StateGraph with the State class we defined\n",
        "builder = StateGraph(state)\n",
        "#add our nodes and edges.\n",
        "builder.add_node(\"node1\", node1)\n",
        "builder.add_node(\"node2\", node2)\n",
        "builder.add_node(\"node3\", node3)\n",
        "# use the START Node, a special node that sends user input to the graph, to indicate where to start our graph\n",
        "builder.add_edge(START, \"node1\")\n",
        "builder.add_conditional_edges(\"node1\", decide_mood)\n",
        "builder.add_edge(\"node2\", END)\n",
        "builder.add_edge(\"node3\", END)\n",
        "\n",
        "#Add\n",
        "graph = builder.compile()\n",
        "#view\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "OVZm88Z3h-B9",
        "outputId": "54e3fc06-34ee-489b-ccf4-932645dd8201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph.invoke({\"graph_state\" : \"สวัสดี ฉันชื่อขวัญ\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMYEjLJBkSVR",
        "outputId": "9afe0719-cb0f-4893-e07e-33c3cb617f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "node1------------------\n",
            "node2------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'graph_state': 'สวัสดี ฉันชื่อขวัญฉันนั้นสบายดี'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "YJaz5BVzhFvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chain**\n",
        "built a simple graph with nodes, normal edges, and conditional edges"
      ],
      "metadata": {
        "id": "IxetkYyYe0MN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Message**\n",
        "\n",
        "Chat model llm can use Message which capture for different role within conversation, Langchain also support massage type (HumanMessage, AI Message, SystemMessage, ToolMessage) All type is define or represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Let's create a list of messages.\n",
        "\n",
        "Each message can be supplied with a few things:\n",
        "\n",
        "content - content of the message\n",
        "\n",
        "*   content - content of the message\n",
        "*   name - optionally, a message author\n",
        "*   response_metadata - optionally, a dict of metadata (e.g., often populated by model provider for AIMessages)\n"
      ],
      "metadata": {
        "id": "wmfkdPyBfJ9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_openai langchain_core langgraph"
      ],
      "metadata": {
        "id": "7us5Zaawgb00"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from langchain_core.messages import HumanMessage, AIMessage"
      ],
      "metadata": {
        "id": "eT8sUvCKhe0g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = [AIMessage(content=f\"Thailand is capital city is Bangkok\", name=\"model\")]\n",
        "message.append(HumanMessage(content=\"yes, Bangkok\", name=\"kwan\"))\n",
        "message.append(AIMessage(content=f\"Is it Bangkok ? not Chiang Mai\", name=\"model\"))\n",
        "message.append(HumanMessage(content=\"no Chiang Mai, just provice in Thailand\", name=\"kwan\"))\n",
        "message.append(AIMessage(content=f\"Thanks for good information\", name=\"model\"))\n",
        "\n",
        "for m in message:\n",
        "  m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsMWUML4h2Cq",
        "outputId": "195b2591-3d60-480e-8080-039904f34bed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: model\n",
            "\n",
            "Thailand is capital city is Bangkok\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "Name: kwan\n",
            "\n",
            "yes, Bangkok\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: model\n",
            "\n",
            "Is it Bangkok ? not Chiang Mai\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "Name: kwan\n",
            "\n",
            "no Chiang Mai, just provice in Thailand\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: model\n",
            "\n",
            "Thanks for good information\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat Model\n",
        "\n",
        "Chat model can use all type message that we mention before, let's do it +++++++\n"
      ],
      "metadata": {
        "id": "oQOTbuSZjq_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPcEKEQuk5jb",
        "outputId": "eb8e9e8f-1f9a-40a4-bee3-b71c576869bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load chat model and invoke with list message that i created before"
      ],
      "metadata": {
        "id": "WWkSV922lvXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "result = llm.invoke(message)\n",
        "type(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "QpWyXYWKl-VR",
        "outputId": "68b3969c-ab4d-4b47-853f-1c897cc5823a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.messages.ai.AIMessage</b><br/>def __init__(content: Union[str, list[Union[str, dict]]], **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_core/messages/ai.py</a>Message from an AI.\n",
              "\n",
              "AIMessage is returned from a chat model as a response to a prompt.\n",
              "\n",
              "This message represents the output of the model and consists of both\n",
              "the raw output as returned by the model together standardized fields\n",
              "(e.g., tool calls, usage metadata) added by the LangChain framework.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 141);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NORMm76AngTV",
        "outputId": "53b51e50-4eed-4e24-af36-26e75a6c2d62"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"You're welcome! If you have any more questions about Thailand or anything else, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 61, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-14c91e3c-2db4-44c9-88df-592e993f609e-0', usage_metadata={'input_tokens': 61, 'output_tokens': 21, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.response_metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B06lW00-nklC",
        "outputId": "13f34c96-9aea-43d1-cf4f-62c118d6c198"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 21,\n",
              "  'prompt_tokens': 61,\n",
              "  'total_tokens': 82,\n",
              "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'reasoning_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0},\n",
              "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
              " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
              " 'system_fingerprint': 'fp_72ed7ab54c',\n",
              " 'finish_reason': 'stop',\n",
              " 'logprobs': None}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool"
      ],
      "metadata": {
        "id": "uJNIbTDan8xh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tool is magic item for model, model can interact with external system data, source etc.External system often require in schema or payload rather than natural language.\n",
        "\n",
        "So when i want to blind an API, for example, as a tool i give a model to know an input schema\n",
        "\n",
        "** Model will choose tool from nature language that input from user, and model will return an output following tool's schema"
      ],
      "metadata": {
        "id": "OId9WaDwoSur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#simply pass any Python function into ChatModel.bind_tools(function)."
      ],
      "metadata": {
        "id": "SMBX6PIfzF13"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plus (a: int, b:int) -> int:\n",
        "    \"\"\"plus a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a+b\n",
        "\n",
        "llm_with_tool = llm.bind_tools([plus])"
      ],
      "metadata": {
        "id": "xvG57lZczI4Y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from Now if i passed an input \"what is 5 plus 8 ?\"\n",
        "\n",
        "will see tool call return\n",
        "\n",
        "\n",
        "The tool call has specific arguments that match the input schema of our function along with the name of the function to call.\n",
        "\n",
        "{'arguments': '{\"a\":5,\"b\":8}', 'name': 'plus'}"
      ],
      "metadata": {
        "id": "mDuHinJn0qcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_call = llm_with_tool.invoke([HumanMessage(content=\"What is 5 plus 8 ?\",name=\"kwan\")])"
      ],
      "metadata": {
        "id": "CkMm3ArP1UtY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_call"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJjtrHOF12ok",
        "outputId": "83c29629-9efd-4fd4-9f10-dec926ed1238"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_VpyNjWaFB3yVOdQbU1o8I4uG', 'function': {'arguments': '{\"a\":5,\"b\":8}', 'name': 'plus'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 63, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-196cb269-3ee2-4563-8602-256760d2ecab-0', tool_calls=[{'name': 'plus', 'args': {'a': 5, 'b': 8}, 'id': 'call_VpyNjWaFB3yVOdQbU1o8I4uG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 63, 'output_tokens': 18, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_call.additional_kwargs['tool_calls']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I0_TN1c2B49",
        "outputId": "de6ed3b9-0259-4084-ed76-9ac1314b9723"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'call_VpyNjWaFB3yVOdQbU1o8I4uG',\n",
              "  'function': {'arguments': '{\"a\":5,\"b\":8}', 'name': 'plus'},\n",
              "  'type': 'function'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using messages as state\n",
        "\n",
        "from first about LangGraph now i can use message in our graph state.\n",
        "Let's Define our state, MessageState as Typedict with a singlekey:message\n",
        "\n",
        "Message is a simple list that we define before (Bangkok is capital city in Thailand )\n"
      ],
      "metadata": {
        "id": "9lAPUhvt2UC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "from langchain_core.messages import AnyMessage\n",
        "\n",
        "class MessagesState(TypedDict):\n",
        "  message : list[AnyMessage]"
      ],
      "metadata": {
        "id": "75Y9dRFi30bB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reducers\n",
        "\n",
        "Problem Alert !!!!!!!!!!!!!!\n",
        "\n",
        "\n",
        "As discuss before each node will return a new value for our state key messages.\n",
        "\n",
        "But, this new value will will override the prior messages value.\n",
        "\n",
        "As our graph runs, want to append messages to to our messages state key.\n",
        "\n",
        "#use reducer functions address this to fix this problem ...\n",
        "\n",
        "Reducers allow to specify how state updates are performed\n",
        "\n",
        "If no reducer function is specified, then it is assumed that updates to the key should override it as before.\n",
        "\n",
        "But, to append messages, we can use the pre-built add_messages reducer.\n",
        "\n",
        "This ensures that any messages are appended to the existing list of messages.\n",
        "\n",
        "An annotate simply need to annotate our messages key with the add_messages reducer function as metadata."
      ],
      "metadata": {
        "id": "yn4rIbRd4R3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class MessagesState(TypedDict):\n",
        "  message : Annotated[list[AnyMessage], add_messages]"
      ],
      "metadata": {
        "id": "tkHE4gr15olZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since have list of message in graph state is common, LangGraph has pre-built MessageState\n",
        "\n",
        "Let's see what is in MessageState:\n",
        "\n",
        "\n",
        "*   With a pre-build single messages key\n",
        "*   This is a list of AnyMessage objects\n",
        "*   It uses the add_messages reducer\n"
      ],
      "metadata": {
        "id": "gfjsshz18Acz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually use MessagesState because it is less verbose than defining a custom TypedDict, as shown above."
      ],
      "metadata": {
        "id": "9_H9A5aR8yL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import MessagesState\n",
        "\n",
        "class MessagesState(MessagesState)\n",
        "  # Add any keys needed beyond messages, which is pre-built\n",
        "  pass"
      ],
      "metadata": {
        "id": "RWOXYzg39Ma-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To go a bit deeper, to can see how the add_messages reducer works in isolation."
      ],
      "metadata": {
        "id": "e4owxYmj9W3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_messages = [AIMessage(content=f\"Hi how can i assistant you ?\", name=\"model\"),\n",
        "                    HumanMessage(content=\"Hi, i'm looking for information to make a trip for vacation in Thailand\", name=\"kwan\")]\n",
        "\n",
        "#new message add\n",
        "new_message = AIMessage(content=\"Sure, i will looking for information about your trip. How many day of your trip\", model=\"model\")\n",
        "\n",
        "#test\n",
        "add_messages(initial_messages, new_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lP3lD__9eJN",
        "outputId": "8f6f9904-dce3-4005-e18c-3a89db11c56b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='Hi how can i assistant you ?', additional_kwargs={}, response_metadata={}, name='model', id='576078f2-19e1-4885-b8d4-e95eac8d2ac2'),\n",
              " HumanMessage(content=\"Hi, i'm looking for information to make a trip for vacation in Thailand\", additional_kwargs={}, response_metadata={}, name='kwan', id='ac5eaa0c-fab3-4ccb-974d-823ca8c48563'),\n",
              " AIMessage(content='Sure, i will looking for information about your trip. How many day of your trip', additional_kwargs={}, response_metadata={}, id='95b12b6f-28cc-4bbf-84a4-1c67974c334c', model='model')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our graph\n",
        "\n",
        "Now, lets use MessagesState with a graph."
      ],
      "metadata": {
        "id": "vGkkBEBQ-z-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "#node\n",
        "def tool_call_llm (state: MessagesState):\n",
        "    return {\"message\" : llm_with_tool.invoke(state['message'])}\n",
        "\n",
        "#build Graph\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"tool_call_llm\", tool_call_llm)\n",
        "builder.add_edge(START, \"tool_call_llm\")\n",
        "builder.add_edge(\"tool_call_llm\", END)\n",
        "graph = builder.compile()\n",
        "\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "JKYtaB8f-4so",
        "outputId": "c2615322-8929-4818-c20f-177f5c76c965"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#If pass in Hello!, the LLM responds without any tool calls.\n",
        "message = graph.invoke({\"message\" : [HumanMessage(content=\"Hello!\")]})\n",
        "for m in message['message']:\n",
        "  m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XYy2akcA6Yc",
        "outputId": "95f808ba-901f-4158-ed10-a25a3b98b466"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hello!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The LLM chooses to use a tool when it determines that the input or task requires the functionality provided by that tool.\n",
        "message = graph.invoke({\"message\" : [HumanMessage(content=\"what is 48 plus 27\")]})\n",
        "for m in message['message']:\n",
        "  m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKgFBEtFBkRk",
        "outputId": "211ec259-acf2-4b9a-a265-3569b15c49d9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "what is 48 plus 27\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  plus (call_0hOwGn22mV5Dh3vmHInTXKKM)\n",
            " Call ID: call_0hOwGn22mV5Dh3vmHInTXKKM\n",
            "  Args:\n",
            "    a: 48\n",
            "    b: 27\n"
          ]
        }
      ]
    }
  ]
}